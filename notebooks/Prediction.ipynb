{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets.mpr_dataset import MPR_Dataset,MPR_Dataset_H5, MPR_Dataset_New_Test, MPR_Dataset_LSTM\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from models import ShuffleNetv2, AttentionShuffleNetV2\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from ast import literal_eval\n",
    "# from visualize_results import label_predictions_to_images\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from torch.nn.functional import softmax \n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '.'\n",
    "with open(p + '/config.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "config['device'] = 'cpu'\n",
    "root_dir = config[\"data\"][\"root_dir\"]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    MPR_Dataset(root_dir, partition=\"test\", config=config[\"data\"], transform=transform), shuffle=False,\n",
    "    batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = ShuffleNetv2(n_classes=3)\n",
    "# PATH_WEIGHTS = 'best_model_shufflenetv2.pth'\n",
    "# PATH_WEIGHTS = 'best_model_only_artery.pth'\n",
    "PATH_WEIGHTS = '/home/petryshak/CoronaryArteryPlaqueIdentification/experiments_replication/exp7/models/model_model_6_val_loss=1.138445.pth'\n",
    "PATH_WEIGHTS = '/home/petryshak/CoronaryArteryPlaqueIdentification/experiments_replication/only_lad_label_smoothing/models/model_model_20_val_f1=0.6245107.pth'\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(PATH_WEIGHTS))#, map_location={'cuda:0': 'cpu'}))\n",
    "# model.load_state_dict(torch.load(PATH_WEIGHTS,map_location={'cuda:0': 'cpu'}))\n",
    "# model.model.fc = nn.Sequential()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7185996863324a5197cee1067ec936d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7409), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = [] \n",
    "probas = []\n",
    "for step, (x, y) in enumerate(tqdm(test_loader)):\n",
    "    x = x.to(device)\n",
    "    y = y\n",
    "    with torch.no_grad():\n",
    "        output = model(x)\n",
    "        softmax_output = softmax(output, dim=1)\n",
    "        \n",
    "        _, predicted = torch.max(softmax_output, 1)\n",
    "        if pd.isnull(predicted.cpu().detach().numpy()):\n",
    "            print(predicted)\n",
    "        predictions.extend(predicted.cpu().detach().numpy())\n",
    "        probas.extend(softmax_output.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7409, 7409)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_test_df = pd.read_csv(\"/home/petryshak/CoronaryArteryPlaqueIdentification/data/all_branches_with_pda_plv/test/labels.csv\")\n",
    "p_test_df = test_loader.dataset.df\n",
    "# p_test_df = test_loader.df\n",
    "# p_test_df = p_test_df.dropna()\n",
    "p_test_df = p_test_df.reset_index()\n",
    "p_test_df['PRED'] = pd.Series(predictions)\n",
    "p_test_df['PROBAS'] = pd.Series(probas)\n",
    "# p_test_df[\"STENOSIS_SCORE\"] = p_test_df[\"STENOSIS_SCORE\"].apply(literal_eval)\n",
    "p_test_df['PATIENT'] = p_test_df['IMG_PATH'].apply(lambda s: s.split('/')[1])\n",
    "mapper = {}\n",
    "for group, values in config['data']['groups'].items():\n",
    "    for value in values:\n",
    "        mapper[value] = group\n",
    "p_test_df[\"LABELS\"] = p_test_df[\"STENOSIS_SCORE\"].apply(lambda x: max([mapper[el] for el in x])).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test_df.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test_df['PROBAS'][p_test_df['PROBAS'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test_df.to_csv('only_lad_label_smoothing_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# df = pd.read_csv('only_lad_cross_entropy_test.csv')\n",
    "p_test_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(p_test_df['LABELS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts((p_test_df['PRED'] == 1) & (p_test_df['LABELS'] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.value_counts(p_test_df['PRED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_artery = {'LAD': ['D-1', 'D-2', 'LAD', 'D-3', '2D-2', 'D-1Original', 'LADOriginal', 'D-4'],\n",
    "#                    'LCX': ['LCX', 'OM-2', 'OM-1', 'OM-3', 'OM', 'LCX-PLB', 'LCX-PDA', 'PLV_LCX', 'PDA_LCX'],\n",
    "#                    'RCA': ['RCA', 'RCA-PLB', 'RCA-PDA', 'PLV_RCA']}\n",
    "    \n",
    "# p_test_df['artery'] = p_test_df['ARTERY_SECTION'].apply(lambda x: [k for k in dict_artery.keys() if x in dict_artery[k]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test_df.groupby('ARTERY_SECTION').count().LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(col_section, col_ids, col_preds, col_labels):\n",
    "    \"\"\"\n",
    "    Calculate final auc and f1 metrics on three levels: per patient, per section and per artery\n",
    "    :return: {dict} each metric as a key and its calculated metric as a value\n",
    "    \"\"\"\n",
    "    assert len(col_section) == len(col_ids) == len(col_preds) == len(col_labels)\n",
    "\n",
    "    metrics = {'ACC_section': 0, 'ACC_patient': 0, 'ACC_artery': 0, 'F1_section': 0, 'F1_patient': 0, 'F1_artery': 0}\n",
    "    dict_artery = {'LAD': ['D-1', 'D-2', 'LAD', 'D-3', '2D-2', 'D-1Original', 'LADOriginal', 'D-4'],\n",
    "                   'LCX': ['LCX', 'OM-2', 'OM-1', 'OM-3', 'OM', 'LCX-PLB', 'LCX-PDA', 'PLV_LCX', 'PDA_LCX'],\n",
    "                   'RCA': ['RCA', 'RCA-PLB', 'RCA-PDA', 'PLV_RCA']}\n",
    "    \n",
    "    df = pd.concat([col_ids, col_section, col_preds, col_labels], axis=1)\n",
    "    df = df.rename(columns={col_section.name: 'section', col_ids.name: 'patient', col_preds.name:\n",
    "        'preds', col_labels.name: 'labels'})\n",
    "\n",
    "    df['artery'] = df['section'].apply(lambda x: [k for k in dict_artery.keys() if x in dict_artery[k]][0])\n",
    "\n",
    "    # SECTION\n",
    "    section_labels =  df[['preds', 'labels','section', 'artery','patient']].groupby(['patient', 'section']).agg('max')\n",
    "    preds_section = df[['preds', 'labels','section','artery', 'patient']].groupby(['patient', 'section']).agg(lambda x: x.value_counts().index[0])\n",
    "\n",
    "    acc = accuracy_score(preds_section['preds'], section_labels['labels'])\n",
    "    f1 = f1_score(preds_section['preds'], section_labels['labels'], average='weighted')\n",
    "    metrics['ACC_section'], metrics['F1_section'] = acc, f1\n",
    "\n",
    "    # ARTERY\n",
    "    sect = section_labels.reset_index()\n",
    "    artery_labels = sect.groupby(['patient', 'artery']).agg('max')['labels']\n",
    "    preds_artery = preds_section.reset_index().groupby(['patient', 'artery']).agg('max')['preds'] #x.value_counts().index[0])['preds']\n",
    "    acc = accuracy_score(preds_artery, artery_labels)\n",
    "    f1 = f1_score(preds_artery, artery_labels, average='weighted')\n",
    "    metrics['ACC_artery'], metrics['F1_artery'] = acc, f1\n",
    "    \n",
    "    # PATIENT\n",
    "    art = artery_labels.reset_index()\n",
    "    patient_labels = art.groupby(['patient']).agg('max')['labels']    \n",
    "#     print(preds_artery.reset_index())\n",
    "    preds_patient = preds_artery.reset_index().groupby(['patient']).agg('max' )['preds'] #x.value_counts().index[0])['preds']\n",
    "    acc = accuracy_score(preds_patient, patient_labels)\n",
    "    f1 = f1_score(preds_patient, patient_labels, average='weighted')\n",
    "    metrics['ACC_patient'], metrics['F1_patient'] = acc, f1\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = p_test_df.dropna()\n",
    "# df = df[df['ARTERY_SECTION'].isin(['LAD'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" LR scheduler\"\"\"\n",
    "calculate_metrics(df['ARTERY_SECTION'], df['PATIENT'], df['PRED'], df['LABELS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" LR scheduler\"\"\"\n",
    "calculate_metrics(p_test_df['ARTERY_SECTION'], p_test_df['PATIENT'], p_test_df['PRED'], p_test_df['LABELS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group and analyze predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model_model_34_val_f1=0.9360136.pth\"\"\"\n",
    "calculate_metrics(p_test_df['ARTERY_SECTION'], p_test_df['PATIENT'], p_test_df['PRED'], p_test_df['LABELS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for segm in p_test_df['ARTERY_SECTION'].unique():\n",
    "    print('ARTERY SEGMENT: {}'.format(segm))\n",
    "    df = p_test_df[p_test_df['ARTERY_SECTION']==segm]\n",
    "    rec_dict = calculate_metrics(df['ARTERY_SECTION'], df['PATIENT'], df['PRED'], df['LABELS'])\n",
    "    print(rec_dict)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
